{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part1: Predicting Molecular Properties\n",
    "\n",
    "\n",
    "## Deep learning on graphs: \n",
    "\n",
    "In this hands-on exercise, we will guide you to design and train your first Graph Neural Network. We will focus here on a graph classification task. In this setting, you're given a set of graphs associated with a label. The goal is to model this set of graphs in order to extract relevant information from 1. the graph topology and 2. the node features to predict the associated label. In this example, the graphs are molecules where the nodes are the atoms and the edges the chemical bonds. More specifically, we are using the MUTAG dataset that consists of 188 chemical compounds divided into two \n",
    "classes according to their mutagenic effect on a bacterium. \n",
    "\n",
    "## Objectives:\n",
    "\n",
    "- Familiarise yourself with the concept of graph. \n",
    "- Introduce the Deep Graph Library (DGL) -- the de facto python library for learning on graphs\n",
    "- Design from scratch an instance of GNN: the Graph Isomorphism Network (GIN)\n",
    "- Train a graph classification task: predicting the mutagenicity of a molecule \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.) Build a graph in DGL: the `DGLGraph`\n",
    "- Declare a graph is as simple as `g = dgl.DGLGraph()`\n",
    "- Add nodes with `add_nodes()`\n",
    "- Add egdes with `add_edges()`\n",
    "- Add node features using the `ndata` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "/Users/gja/opt/anaconda3/lib/python3.7/site-packages/dgl/base.py:45: DGLWarning: Detected an old version of PyTorch. Suggest using torch>=1.5.0 for the best experience.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has the following properties:\n",
      "- 10 nodes\n",
      "- \"attr\" with [10, 5] node features\n",
      "- 7 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gja/opt/anaconda3/lib/python3.7/site-packages/dgl/base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import dgl \n",
    "import numpy as np \n",
    "import torch \n",
    "\n",
    "# 1. declare a graph \n",
    "graph = dgl.DGLGraph()\n",
    "\n",
    "# 2. add 10 nodes\n",
    "graph.add_nodes(10)\n",
    "\n",
    "# 3. add 7 random edges \n",
    "from_ = np.random.randint(0, 9, 7)\n",
    "to_ = np.random.randint(0, 9, 7)\n",
    "graph.add_edges(from_, to_)\n",
    "\n",
    "# 4. add node features \n",
    "graph.ndata['attr'] = torch.randn(10, 5)\n",
    "\n",
    "def print_graph_properties(g):\n",
    "  print('Graph has the following properties:')\n",
    "  print('- {} nodes'.format(g.number_of_nodes()))\n",
    "  for key, val in g.ndata.items():\n",
    "    print('- \"{}\" with {} node features'.format(key, list(val.shape)))\n",
    "  print('- {} edges'.format(g.number_of_edges()))\n",
    "  \n",
    "print_graph_properties(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.) Dataloading with DGL:\n",
    "\n",
    "### DGL built-in dataloader \n",
    "- DGL provides a set of built-in dataloader for common datasets (eg `dgl.data.GINDataset`, `dgl.data.TUDataset`)\n",
    "- This module is analogous to the `torchvision` library that provides an API to load popular computer vision datasets. \n",
    "\n",
    "### DGL is built around `networkx` & PyTorch \n",
    "- Allows to (partially) use the `networkx` API when dealing with the graph objects \n",
    "- Conversion from `DGLGraph` to networkx `Graph` is straightforward\n",
    "- Allows to use the PyTorch API when manipulating the node & edges features \n",
    "\n",
    "### How to build a batch of graphs: The DGL `batch` \n",
    "- For graph classification, as in image classification, we need to build a batch, ie a set of samples that are fed to the model. \n",
    "- As opposed to image classification where each sample can be resized and padded to obtain the same size, adopting the same approach with graphs is not feasible. \n",
    "- A DGL batch is built using the observation that a set of N graphs can be represented as one large disconnected graph made of N connected components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has the following properties:\n",
      "- 23 nodes\n",
      "- \"attr\" with [23, 7] node features\n",
      "- \"label\" with [23] node features\n",
      "- 54 edges\n"
     ]
    }
   ],
   "source": [
    "import dgl \n",
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "import random \n",
    "\n",
    "# 1. load the data: graphs and labels \n",
    "data = dgl.data.GINDataset('MUTAG', self_loop=False)\n",
    "\n",
    "# 2. Inspect manually the data by printing one of the samples\n",
    "g, label = data[0]\n",
    "print_graph_properties(g)\n",
    "\n",
    "# 3. Batchify and train/val split the data\n",
    "data = list(zip(data.graphs, data.labels))\n",
    "random.shuffle(data)\n",
    "train_data = data[:int(len(data)* 0.7)]\n",
    "val_data = data[int(len(data)*0.7):]\n",
    "batch_size = 8\n",
    "\n",
    "def collate(batch):\n",
    "  g = dgl.batch([example[0] for example in batch])\n",
    "  l = torch.LongTensor([example[1] for example in batch])\n",
    "  return g, l\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size, shuffle=True, collate_fn=collate)\n",
    "val_dataloader = DataLoader(train_data, batch_size, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C.) Designing a DGL model\n",
    "\n",
    "### Object oriented approach\n",
    "- Define your Graph Neural Network layer as a python object \n",
    "- Define a model object that is:\n",
    "  - instantiating several GNN layers \n",
    "  - implementing a global pooling operation, e.g., with a sum\n",
    "  - projecting the graph embedding to the number of classes using an MLP\n",
    "  \n",
    "### The Graph Isomorphism Network\n",
    "- The GIN proposes to update each node as:\n",
    "\\begin{equation}\n",
    "h_v^{(k)} = \\mbox{MLP}^{(k)} (h_v^{(k-1)} + \\sum_{u \\in N(v)} h_u^{(k-1)})\n",
    "\\end{equation}\n",
    "- The graph-level embedding is then obtained using:\n",
    "\\begin{equation}\n",
    "h_G = \\sum_{v \\in V} h_v^{(k)}\n",
    "\\end{equation}\n",
    "- The DGL library also provides a high-level API to directly load Graph Neural Network layers in the `dgl.nn.pytorch.conv` module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class GINLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, node_dim, out_dim):\n",
    "        \"\"\"\n",
    "        Implementation of a GIN (Graph Isomorphism Network) layer.\n",
    "\n",
    "        Original paper:\n",
    "          - How Powerful are Graph Neural Networks: https://arxiv.org/abs/1810.00826\n",
    "          - Author's public implementation: https://github.com/weihua916/powerful-gnns\n",
    "          \n",
    "        :param node_dim: (int) input dimension of the node features\n",
    "        :param out_dim: (int) output dimension of the node features \n",
    "        \"\"\"\n",
    "        \n",
    "        super(GINLayer, self).__init__()\n",
    "\n",
    "        self.batchnorm_h = nn.BatchNorm1d(out_dim)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "        nn.Linear(node_dim, out_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(out_dim, out_dim),\n",
    "      )\n",
    "\n",
    "    def msg_fn(self, edges):\n",
    "        \"\"\"\n",
    "        Message of each node\n",
    "        \"\"\"\n",
    "        return {'msg': edges.src['h']}\n",
    "      \n",
    "    def reduce_fn(self, nodes):\n",
    "        \"\"\"\n",
    "        For each node, aggregate the nodes using a reduce function.\n",
    "        Current supported functions are sum and mean.\n",
    "        \"\"\"\n",
    "        accum = torch.sum(nodes.mailbox['msg'], dim=1)\n",
    "        return {'agg_msg': accum}\n",
    "\n",
    "    def node_update_fn(self, nodes):\n",
    "        \"\"\"\n",
    "        Node update function\n",
    "        \"\"\"\n",
    "        h = nodes.data['h']\n",
    "        h = self.mlp(h)\n",
    "        h = F.relu(h)\n",
    "        return {'h_out': h}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        \"\"\"\n",
    "        Forward-pass of a GIN layer.\n",
    "        :param g: (DGLGraph) graph to process\n",
    "        :param h: (FloatTensor) node features\n",
    "        \"\"\"\n",
    "\n",
    "        # 1. set node features to g\n",
    "        g.ndata['h'] = h\n",
    "\n",
    "        # 2. message passing \n",
    "        g.update_all(self.msg_fn, self.reduce_fn)\n",
    "        g.ndata['h'] = g.ndata.pop('agg_msg') + g.ndata.pop('h')\n",
    "        g.apply_nodes(func=self.node_update_fn)\n",
    "\n",
    "        # 3. pop node features & apply batch norm \n",
    "        h = g.ndata.pop('h_out')\n",
    "        h = self.batchnorm_h(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "      \n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, node_dim, out_dim, num_layers, num_classes):\n",
    "      super(Model, self).__init__()\n",
    "      \n",
    "      # 1. define series of GNN layer \n",
    "      self.layers = nn.ModuleList()\n",
    "      for layer_id in range(num_layers):\n",
    "        self.layers.append(GINLayer(node_dim if layer_id == 0 else out_dim, out_dim))\n",
    "        \n",
    "      # 2. define classifier \n",
    "      self.classifier = nn.Sequential(\n",
    "        nn.Linear(out_dim, out_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(out_dim, num_classes)\n",
    "      )\n",
    "\n",
    "    def forward(self, g):\n",
    "      \n",
    "      # 1. loop over the GNN layers \n",
    "      h = g.ndata['attr'].type('torch.FloatTensor')\n",
    "      for layer in self.layers:\n",
    "        h = layer(g, h)\n",
    "        \n",
    "      # 2. apply pooling to build fixed-size representation\n",
    "      g.ndata['h'] = h\n",
    "      g_emb = dgl.sum_nodes(g, 'h')\n",
    "      \n",
    "      # 3. apply classifier to get the logits \n",
    "      logits = self.classifier(g_emb)\n",
    "      \n",
    "      return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.) Define the training and testing loop\n",
    "\n",
    "### Use classic PyTorch training loop \n",
    "- Define the model parameters (num layers, GNN dimensions)\n",
    "- Define the training parameters (optimizer, learning rate, weight decay, number of epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 0: 100%|██████████| 17/17 [00:00<00:00, 35.89batch/s]\n",
      "Epoch validation 0: 100%|██████████| 17/17 [00:00<00:00, 61.75batch/s]\n",
      "Epoch training 1:  24%|██▎       | 4/17 [00:00<00:00, 37.94batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.9852415919303894 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 1: 100%|██████████| 17/17 [00:00<00:00, 26.17batch/s]\n",
      "Epoch validation 1: 100%|██████████| 17/17 [00:00<00:00, 64.75batch/s]\n",
      "Epoch training 2:  18%|█▊        | 3/17 [00:00<00:00, 29.69batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=1.2128177881240845 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 2: 100%|██████████| 17/17 [00:00<00:00, 44.82batch/s]\n",
      "Epoch validation 2: 100%|██████████| 17/17 [00:00<00:00, 74.27batch/s]\n",
      "Epoch training 3:  29%|██▉       | 5/17 [00:00<00:00, 47.86batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=1.3664636611938477 | accuracy=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 3: 100%|██████████| 17/17 [00:00<00:00, 45.84batch/s]\n",
      "Epoch validation 3: 100%|██████████| 17/17 [00:00<00:00, 72.21batch/s]\n",
      "Epoch training 4:  35%|███▌      | 6/17 [00:00<00:00, 53.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=2.6499853134155273 | accuracy=0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 4: 100%|██████████| 17/17 [00:00<00:00, 43.79batch/s]\n",
      "Epoch validation 4: 100%|██████████| 17/17 [00:00<00:00, 69.58batch/s]\n",
      "Epoch training 5:  18%|█▊        | 3/17 [00:00<00:00, 24.46batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.8064854145050049 | accuracy=0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 5: 100%|██████████| 17/17 [00:00<00:00, 25.32batch/s]\n",
      "Epoch validation 5: 100%|██████████| 17/17 [00:00<00:00, 63.16batch/s]\n",
      "Epoch training 6:  29%|██▉       | 5/17 [00:00<00:00, 39.86batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.4432724416255951 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 6: 100%|██████████| 17/17 [00:00<00:00, 37.19batch/s]\n",
      "Epoch validation 6: 100%|██████████| 17/17 [00:00<00:00, 52.23batch/s]\n",
      "Epoch training 7:  24%|██▎       | 4/17 [00:00<00:00, 31.01batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.33394527435302734 | accuracy=0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 7: 100%|██████████| 17/17 [00:00<00:00, 37.07batch/s]\n",
      "Epoch validation 7: 100%|██████████| 17/17 [00:00<00:00, 81.05batch/s]\n",
      "Epoch training 8:  35%|███▌      | 6/17 [00:00<00:00, 52.74batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.36344975233078003 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 8: 100%|██████████| 17/17 [00:00<00:00, 47.09batch/s]\n",
      "Epoch validation 8: 100%|██████████| 17/17 [00:00<00:00, 73.89batch/s]\n",
      "Epoch training 9:  29%|██▉       | 5/17 [00:00<00:00, 46.95batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.39573484659194946 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 9: 100%|██████████| 17/17 [00:00<00:00, 22.77batch/s]\n",
      "Epoch validation 9: 100%|██████████| 17/17 [00:00<00:00, 43.97batch/s]\n",
      "Epoch training 10:  24%|██▎       | 4/17 [00:00<00:00, 38.19batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=1.4569710493087769 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 10: 100%|██████████| 17/17 [00:00<00:00, 46.81batch/s]\n",
      "Epoch validation 10: 100%|██████████| 17/17 [00:00<00:00, 81.92batch/s]\n",
      "Epoch training 11:  35%|███▌      | 6/17 [00:00<00:00, 53.08batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.8308783769607544 | accuracy=0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 11: 100%|██████████| 17/17 [00:00<00:00, 42.02batch/s]\n",
      "Epoch validation 11: 100%|██████████| 17/17 [00:00<00:00, 79.13batch/s]\n",
      "Epoch training 12:  29%|██▉       | 5/17 [00:00<00:00, 49.53batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.6420832276344299 | accuracy=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 12: 100%|██████████| 17/17 [00:00<00:00, 45.30batch/s]\n",
      "Epoch validation 12: 100%|██████████| 17/17 [00:00<00:00, 76.31batch/s]\n",
      "Epoch training 13:  35%|███▌      | 6/17 [00:00<00:00, 52.95batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=2.1337502002716064 | accuracy=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 13: 100%|██████████| 17/17 [00:00<00:00, 47.89batch/s]\n",
      "Epoch validation 13: 100%|██████████| 17/17 [00:00<00:00, 80.12batch/s]\n",
      "Epoch training 14:  29%|██▉       | 5/17 [00:00<00:00, 47.85batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.40721896290779114 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 14: 100%|██████████| 17/17 [00:00<00:00, 40.40batch/s]\n",
      "Epoch validation 14: 100%|██████████| 17/17 [00:00<00:00, 56.25batch/s]\n",
      "Epoch training 15:  24%|██▎       | 4/17 [00:00<00:00, 35.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=1.2882148027420044 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 15: 100%|██████████| 17/17 [00:00<00:00, 46.63batch/s]\n",
      "Epoch validation 15: 100%|██████████| 17/17 [00:00<00:00, 80.47batch/s]\n",
      "Epoch training 16:  29%|██▉       | 5/17 [00:00<00:00, 49.54batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.29239732027053833 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 16: 100%|██████████| 17/17 [00:00<00:00, 54.28batch/s]\n",
      "Epoch validation 16: 100%|██████████| 17/17 [00:00<00:00, 86.06batch/s]\n",
      "Epoch training 17:  35%|███▌      | 6/17 [00:00<00:00, 54.52batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.5381152629852295 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 17: 100%|██████████| 17/17 [00:00<00:00, 50.53batch/s]\n",
      "Epoch validation 17: 100%|██████████| 17/17 [00:00<00:00, 63.47batch/s]\n",
      "Epoch training 18:  35%|███▌      | 6/17 [00:00<00:00, 58.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.4217666685581207 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 18: 100%|██████████| 17/17 [00:00<00:00, 49.95batch/s]\n",
      "Epoch validation 18: 100%|██████████| 17/17 [00:00<00:00, 75.57batch/s]\n",
      "Epoch training 19:  35%|███▌      | 6/17 [00:00<00:00, 53.32batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.3408812880516052 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 19: 100%|██████████| 17/17 [00:00<00:00, 44.29batch/s]\n",
      "Epoch validation 19: 100%|██████████| 17/17 [00:00<00:00, 49.24batch/s]\n",
      "Epoch training 20:  12%|█▏        | 2/17 [00:00<00:00, 18.38batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.2765464186668396 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 20: 100%|██████████| 17/17 [00:00<00:00, 42.29batch/s]\n",
      "Epoch validation 20: 100%|██████████| 17/17 [00:00<00:00, 88.80batch/s]\n",
      "Epoch training 21:  29%|██▉       | 5/17 [00:00<00:00, 47.59batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.32844609022140503 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 21: 100%|██████████| 17/17 [00:00<00:00, 48.72batch/s]\n",
      "Epoch validation 21: 100%|██████████| 17/17 [00:00<00:00, 88.57batch/s]\n",
      "Epoch training 22:  24%|██▎       | 4/17 [00:00<00:00, 38.74batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.3045073449611664 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 22: 100%|██████████| 17/17 [00:00<00:00, 46.17batch/s]\n",
      "Epoch validation 22: 100%|██████████| 17/17 [00:00<00:00, 87.58batch/s]\n",
      "Epoch training 23:  29%|██▉       | 5/17 [00:00<00:00, 47.07batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.41788700222969055 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 23: 100%|██████████| 17/17 [00:00<00:00, 50.62batch/s]\n",
      "Epoch validation 23: 100%|██████████| 17/17 [00:00<00:00, 77.16batch/s]\n",
      "Epoch training 24:  35%|███▌      | 6/17 [00:00<00:00, 49.50batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.4884737432003021 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 24: 100%|██████████| 17/17 [00:00<00:00, 50.81batch/s]\n",
      "Epoch validation 24: 100%|██████████| 17/17 [00:00<00:00, 47.11batch/s]\n",
      "Epoch training 25:  18%|█▊        | 3/17 [00:00<00:00, 26.63batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.2804396450519562 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 25: 100%|██████████| 17/17 [00:00<00:00, 34.09batch/s]\n",
      "Epoch validation 25: 100%|██████████| 17/17 [00:00<00:00, 76.40batch/s]\n",
      "Epoch training 26:  29%|██▉       | 5/17 [00:00<00:00, 47.53batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.2771628201007843 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 26: 100%|██████████| 17/17 [00:00<00:00, 51.02batch/s]\n",
      "Epoch validation 26: 100%|██████████| 17/17 [00:00<00:00, 71.83batch/s]\n",
      "Epoch training 27:  29%|██▉       | 5/17 [00:00<00:00, 47.01batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=1.1416981220245361 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 27: 100%|██████████| 17/17 [00:00<00:00, 51.70batch/s]\n",
      "Epoch validation 27: 100%|██████████| 17/17 [00:00<00:00, 81.73batch/s]\n",
      "Epoch training 28:  35%|███▌      | 6/17 [00:00<00:00, 55.98batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=2.923941135406494 | accuracy=0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 28: 100%|██████████| 17/17 [00:00<00:00, 46.94batch/s]\n",
      "Epoch validation 28: 100%|██████████| 17/17 [00:00<00:00, 77.85batch/s]\n",
      "Epoch training 29:  29%|██▉       | 5/17 [00:00<00:00, 49.20batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.31355541944503784 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 29: 100%|██████████| 17/17 [00:00<00:00, 48.67batch/s]\n",
      "Epoch validation 29: 100%|██████████| 17/17 [00:00<00:00, 70.14batch/s]\n",
      "Epoch training 30:  24%|██▎       | 4/17 [00:00<00:00, 39.10batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.5259750485420227 | accuracy=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 30: 100%|██████████| 17/17 [00:00<00:00, 34.09batch/s]\n",
      "Epoch validation 30: 100%|██████████| 17/17 [00:00<00:00, 76.98batch/s]\n",
      "Epoch training 31:  35%|███▌      | 6/17 [00:00<00:00, 45.86batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.2741450071334839 | accuracy=0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 31: 100%|██████████| 17/17 [00:00<00:00, 50.32batch/s]\n",
      "Epoch validation 31: 100%|██████████| 17/17 [00:00<00:00, 79.97batch/s]\n",
      "Epoch training 32:  35%|███▌      | 6/17 [00:00<00:00, 53.11batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.29186925292015076 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 32: 100%|██████████| 17/17 [00:00<00:00, 51.26batch/s]\n",
      "Epoch validation 32: 100%|██████████| 17/17 [00:00<00:00, 79.28batch/s]\n",
      "Epoch training 33:  41%|████      | 7/17 [00:00<00:00, 62.39batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.27348893880844116 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 33: 100%|██████████| 17/17 [00:00<00:00, 54.24batch/s]\n",
      "Epoch validation 33: 100%|██████████| 17/17 [00:00<00:00, 85.43batch/s]\n",
      "Epoch training 34:  29%|██▉       | 5/17 [00:00<00:00, 43.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.3187020421028137 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 34: 100%|██████████| 17/17 [00:00<00:00, 48.71batch/s]\n",
      "Epoch validation 34: 100%|██████████| 17/17 [00:00<00:00, 86.85batch/s]\n",
      "Epoch training 35:  29%|██▉       | 5/17 [00:00<00:00, 46.24batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.2808498442173004 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 35: 100%|██████████| 17/17 [00:00<00:00, 41.96batch/s]\n",
      "Epoch validation 35: 100%|██████████| 17/17 [00:00<00:00, 61.32batch/s]\n",
      "Epoch training 36:  18%|█▊        | 3/17 [00:00<00:00, 27.94batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.5361737012863159 | accuracy=0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 36: 100%|██████████| 17/17 [00:00<00:00, 44.67batch/s]\n",
      "Epoch validation 36: 100%|██████████| 17/17 [00:00<00:00, 80.11batch/s]\n",
      "Epoch training 37:  35%|███▌      | 6/17 [00:00<00:00, 57.56batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.7666560411453247 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 37: 100%|██████████| 17/17 [00:00<00:00, 53.52batch/s]\n",
      "Epoch validation 37: 100%|██████████| 17/17 [00:00<00:00, 93.42batch/s]\n",
      "Epoch training 38:  29%|██▉       | 5/17 [00:00<00:00, 49.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.32706600427627563 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 38: 100%|██████████| 17/17 [00:00<00:00, 50.49batch/s]\n",
      "Epoch validation 38: 100%|██████████| 17/17 [00:00<00:00, 87.83batch/s]\n",
      "Epoch training 39:  29%|██▉       | 5/17 [00:00<00:00, 46.66batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.3271639049053192 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 39: 100%|██████████| 17/17 [00:00<00:00, 51.47batch/s]\n",
      "Epoch validation 39: 100%|██████████| 17/17 [00:00<00:00, 79.11batch/s]\n",
      "Epoch training 40:  35%|███▌      | 6/17 [00:00<00:00, 50.31batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.42906635999679565 | accuracy=0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 40: 100%|██████████| 17/17 [00:00<00:00, 52.68batch/s]\n",
      "Epoch validation 40: 100%|██████████| 17/17 [00:00<00:00, 68.57batch/s]\n",
      "Epoch training 41:  29%|██▉       | 5/17 [00:00<00:00, 45.84batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.644992470741272 | accuracy=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 41: 100%|██████████| 17/17 [00:00<00:00, 40.26batch/s]\n",
      "Epoch validation 41: 100%|██████████| 17/17 [00:00<00:00, 75.26batch/s]\n",
      "Epoch training 42:  29%|██▉       | 5/17 [00:00<00:00, 45.63batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.2764170467853546 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 42: 100%|██████████| 17/17 [00:00<00:00, 52.96batch/s]\n",
      "Epoch validation 42: 100%|██████████| 17/17 [00:00<00:00, 77.53batch/s]\n",
      "Epoch training 43:  29%|██▉       | 5/17 [00:00<00:00, 45.43batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.2695302367210388 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 43: 100%|██████████| 17/17 [00:00<00:00, 46.66batch/s]\n",
      "Epoch validation 43: 100%|██████████| 17/17 [00:00<00:00, 87.28batch/s]\n",
      "Epoch training 44:  35%|███▌      | 6/17 [00:00<00:00, 57.95batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.5232007503509521 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 44: 100%|██████████| 17/17 [00:00<00:00, 56.33batch/s]\n",
      "Epoch validation 44: 100%|██████████| 17/17 [00:00<00:00, 87.31batch/s]\n",
      "Epoch training 45:  35%|███▌      | 6/17 [00:00<00:00, 55.36batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.30979233980178833 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 45: 100%|██████████| 17/17 [00:00<00:00, 51.68batch/s]\n",
      "Epoch validation 45: 100%|██████████| 17/17 [00:00<00:00, 84.02batch/s]\n",
      "Epoch training 46:  35%|███▌      | 6/17 [00:00<00:00, 55.46batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.23936156928539276 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 46: 100%|██████████| 17/17 [00:00<00:00, 50.04batch/s]\n",
      "Epoch validation 46: 100%|██████████| 17/17 [00:00<00:00, 55.27batch/s]\n",
      "Epoch training 47:  29%|██▉       | 5/17 [00:00<00:00, 43.00batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.2505817115306854 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 47: 100%|██████████| 17/17 [00:00<00:00, 42.98batch/s]\n",
      "Epoch validation 47: 100%|██████████| 17/17 [00:00<00:00, 83.13batch/s]\n",
      "Epoch training 48:  41%|████      | 7/17 [00:00<00:00, 62.33batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.3549433946609497 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 48: 100%|██████████| 17/17 [00:00<00:00, 51.78batch/s]\n",
      "Epoch validation 48: 100%|██████████| 17/17 [00:00<00:00, 93.87batch/s]\n",
      "Epoch training 49:  29%|██▉       | 5/17 [00:00<00:00, 49.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.29398950934410095 | accuracy=0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch training 49: 100%|██████████| 17/17 [00:00<00:00, 39.53batch/s]\n",
      "Epoch validation 49: 100%|██████████| 17/17 [00:00<00:00, 70.07batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.3667140007019043 | accuracy=0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# with cuda?\n",
    "cuda = torch.cuda.is_available()\n",
    "device = 'cuda:0' if cuda else 'cpu'\n",
    "\n",
    "# declare model\n",
    "model = Model(\n",
    "  node_dim=g.ndata['attr'].shape[1],\n",
    "  out_dim=32,\n",
    "  num_layers=3,\n",
    "  num_classes=2\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# build optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=10e-3,\n",
    "    weight_decay=5e-4\n",
    ")\n",
    "\n",
    "# define loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# training \n",
    "for epoch in range(50):\n",
    "  \n",
    "    # A.) train for 1 epoch \n",
    "    model.train()\n",
    "    for graphs, labels in tqdm(train_dataloader, desc='Epoch training {}'.format(epoch), unit='batch'):\n",
    "\n",
    "        # 1. forward pass\n",
    "        labels = labels.to(device)\n",
    "        logits = model(graphs)\n",
    "\n",
    "        # 2. backward pass\n",
    "        loss = loss_fn(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # B.) validate\n",
    "    model.eval()\n",
    "    all_val_logits = []\n",
    "    all_val_labels = []\n",
    "    for graphs, labels in tqdm(val_dataloader, desc='Epoch validation {}'.format(epoch), unit='batch'):\n",
    "        with torch.no_grad():\n",
    "            labels = labels.to(device)\n",
    "            logits = model(graphs)\n",
    "        all_val_logits.append(logits)\n",
    "        all_val_labels.append(labels)\n",
    "\n",
    "    all_val_logits = torch.cat(all_val_logits).cpu()\n",
    "    all_val_labels = torch.cat(all_val_labels).cpu()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_loss = loss_fn(all_val_logits, all_val_labels).item()\n",
    "        _, predictions = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(predictions.to(int) == labels.to(int))\n",
    "        val_accuracy = correct.item() * 1.0 / len(labels)\n",
    "    print('Validation with loss={} | accuracy={}'.format(val_loss, val_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
