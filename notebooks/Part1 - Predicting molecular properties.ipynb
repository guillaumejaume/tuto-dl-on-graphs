{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part1: Predicting Molecular Properties\n",
    "\n",
    "\n",
    "## Deep learning on graphs: \n",
    "\n",
    "In this hands-on exercise, we will guide you to design and train your first Graph Neural Network. We will focus here on a graph classification task. In this setting, you're given a set of graphs associated with a label. The goal is to model this set of graphs in order to extract relevant information from 1. the graph topology and 2. the node features to predict the associated label. In this example, the graphs are molecules where the nodes are the atoms and the edges the chemical bonds. More specifically, we are using the MUTAG dataset that consists of 188 chemical compounds divided into two \n",
    "classes according to their mutagenic effect on a bacterium. \n",
    "\n",
    "## Objectives:\n",
    "\n",
    "- Familiarise yourself with the concept of graph. \n",
    "- Introduce the Deep Graph Library (DGL) -- the de facto python library for learning on graphs\n",
    "- Design from scratch an instance of GNN: the Graph Isomorphism Network (GIN)\n",
    "- Train a graph classification task: predicting the mutagenicity of a molecule \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.) Build a graph in DGL: the `DGLGraph`\n",
    "- Declare a graph is as simple as `g = dgl.DGLGraph()`\n",
    "- Add nodes with `add_nodes()`\n",
    "- Add egdes with `add_edges()`\n",
    "- Add node features using the `ndata` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "/Users/gja/opt/anaconda3/lib/python3.7/site-packages/dgl/base.py:45: DGLWarning: Detected an old version of PyTorch. Suggest using torch>=1.5.0 for the best experience.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has the following properties:\n",
      "- 10 nodes\n",
      "- \"attr\" with [10, 5] node features\n",
      "- 7 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gja/opt/anaconda3/lib/python3.7/site-packages/dgl/base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import dgl \n",
    "import numpy as np \n",
    "import torch \n",
    "\n",
    "# 1. declare a graph \n",
    "graph = dgl.DGLGraph()\n",
    "\n",
    "# 2. add 10 nodes\n",
    "graph.add_nodes(10)\n",
    "\n",
    "# 3. add 7 random edges \n",
    "from_ = np.random.randint(0, 9, 7)\n",
    "to_ = np.random.randint(0, 9, 7)\n",
    "graph.add_edges(from_, to_)\n",
    "\n",
    "# 4. add node features \n",
    "graph.ndata['attr'] = torch.randn(10, 5)\n",
    "\n",
    "def print_graph_properties(g):\n",
    "  print('Graph has the following properties:')\n",
    "  print('- {} nodes'.format(g.number_of_nodes()))\n",
    "  for key, val in g.ndata.items():\n",
    "    print('- \"{}\" with {} node features'.format(key, list(val.shape)))\n",
    "  print('- {} edges'.format(g.number_of_edges()))\n",
    "  \n",
    "print_graph_properties(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.) Dataloading with DGL:\n",
    "\n",
    "### DGL built-in dataloader \n",
    "- DGL provides a set of built-in dataloader for common datasets (eg `dgl.data.GINDataset`, `dgl.data.TUDataset`)\n",
    "- This module is analogous to the `torchvision` library that provides an API to load popular computer vision datasets. \n",
    "\n",
    "### DGL is built around `networkx` & PyTorch \n",
    "- Allows to (partially) use the `networkx` API when dealing with the graph objects \n",
    "- Conversion from `DGLGraph` to networkx `Graph` is straightforward\n",
    "- Allows to use the PyTorch API when manipulating the node & edges features \n",
    "\n",
    "### How to build a batch of graphs: The DGL `batch` \n",
    "- For graph classification, as in image classification, we need to build a batch, ie a set of samples that are fed to the model. \n",
    "- As opposed to image classification where each sample can be resized and padded to obtain the same size, adopting the same approach with graphs is not feasible. \n",
    "- A DGL batch is built using the observation that a set of N graphs can be represented as one large disconnected graph made of N connected components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has the following properties:\n",
      "- 23 nodes\n",
      "- \"attr\" with [23, 7] node features\n",
      "- \"label\" with [23] node features\n",
      "- 54 edges\n"
     ]
    }
   ],
   "source": [
    "import dgl \n",
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "import random \n",
    "\n",
    "# 1. load the data: graphs and labels \n",
    "data = dgl.data.GINDataset('MUTAG', self_loop=False)\n",
    "\n",
    "# 2. Inspect manually the data by printing one of the samples\n",
    "g, label = data[0]\n",
    "print_graph_properties(g)\n",
    "\n",
    "# 3. Batchify and train/val split the data\n",
    "data = list(zip(data.graphs, data.labels))\n",
    "random.shuffle(data)\n",
    "train_data = data[:int(len(data)* 0.7)]\n",
    "val_data = data[int(len(data)*0.7):]\n",
    "batch_size = 8\n",
    "\n",
    "def collate(batch):\n",
    "  g = dgl.batch([example[0] for example in batch])\n",
    "  l = torch.LongTensor([example[1] for example in batch])\n",
    "  return g, l\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size, shuffle=True, collate_fn=collate)\n",
    "val_dataloader = DataLoader(train_data, batch_size, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C.) Designing a DGL model\n",
    "\n",
    "### Object oriented approach\n",
    "- Define your Graph Neural Network layer as a python object \n",
    "- Define a model object that is:\n",
    "  - instantiating several GNN layers \n",
    "  - implementing a global pooling operation, e.g., with a sum\n",
    "  - projecting the graph embedding to the number of classes using an MLP\n",
    "  \n",
    "### The Graph Isomorphism Network\n",
    "- The GIN proposes to update each node as:\n",
    "\\begin{equation}\n",
    "h_v^{(k)} = \\mbox{MLP}^{(k)} (h_v^{(k-1)} + \\sum_{u \\in N(v)} h_u^{(k-1)})\n",
    "\\end{equation}\n",
    "- The graph-level embedding is then obtained using:\n",
    "\\begin{equation}\n",
    "h_G = \\sum_{v \\in V} h_v^{(k)}\n",
    "\\end{equation}\n",
    "- The DGL library also provides a high-level API to directly load Graph Neural Network layers in the `dgl.nn.pytorch.conv` module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class GINLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, node_dim, out_dim):\n",
    "        \"\"\"\n",
    "        Implementation of a GIN (Graph Isomorphism Network) layer.\n",
    "\n",
    "        Original paper:\n",
    "          - How Powerful are Graph Neural Networks: https://arxiv.org/abs/1810.00826\n",
    "          - Author's public implementation: https://github.com/weihua916/powerful-gnns\n",
    "          \n",
    "        :param node_dim: (int) input dimension of the node features\n",
    "        :param out_dim: (int) output dimension of the node features \n",
    "        \"\"\"\n",
    "        \n",
    "        super(GINLayer, self).__init__()\n",
    "\n",
    "        self.batchnorm_h = nn.BatchNorm1d(out_dim)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "        nn.Linear(node_dim, out_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(out_dim, out_dim),\n",
    "      )\n",
    "\n",
    "    def msg_fn(self, edges):\n",
    "        \"\"\"\n",
    "        Message of each node\n",
    "        \"\"\"\n",
    "        return {'msg': edges.src['h']}\n",
    "      \n",
    "    def reduce_fn(self, nodes):\n",
    "        \"\"\"\n",
    "        For each node, aggregate the nodes using a reduce function.\n",
    "        Current supported functions are sum and mean.\n",
    "        \"\"\"\n",
    "        accum = torch.sum(nodes.mailbox['msg'], dim=1)\n",
    "        return {'agg_msg': accum}\n",
    "\n",
    "    def node_update_fn(self, nodes):\n",
    "        \"\"\"\n",
    "        Node update function\n",
    "        \"\"\"\n",
    "        h = nodes.data['h']\n",
    "        h = self.mlp(h)\n",
    "        h = F.relu(h)\n",
    "        return {'h_out': h}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        \"\"\"\n",
    "        Forward-pass of a GIN layer.\n",
    "        :param g: (DGLGraph) graph to process\n",
    "        :param h: (FloatTensor) node features\n",
    "        \"\"\"\n",
    "\n",
    "        # 1. set node features to g\n",
    "        g.ndata['h'] = h\n",
    "\n",
    "        # 2. message passing \n",
    "        g.update_all(self.msg_fn, self.reduce_fn)\n",
    "        g.ndata['h'] = g.ndata.pop('agg_msg') + g.ndata.pop('h')\n",
    "        g.apply_nodes(func=self.node_update_fn)\n",
    "\n",
    "        # 3. pop node features & apply batch norm \n",
    "        h = g.ndata.pop('h_out')\n",
    "        h = self.batchnorm_h(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "      \n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, node_dim, out_dim, num_layers, num_classes):\n",
    "      super(Model, self).__init__()\n",
    "      \n",
    "      # 1. define series of GNN layer \n",
    "      self.layers = nn.ModuleList()\n",
    "      for layer_id in range(num_layers):\n",
    "        self.layers.append(GINLayer(node_dim if layer_id == 0 else out_dim, out_dim))\n",
    "        \n",
    "      # 2. define classifier \n",
    "      self.classifier = nn.Sequential(\n",
    "        nn.Linear(out_dim, out_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(out_dim, num_classes)\n",
    "      )\n",
    "\n",
    "    def forward(self, g):\n",
    "      \n",
    "      # 1. loop over the GNN layers \n",
    "      h = g.ndata['attr'].type('torch.FloatTensor')\n",
    "      for layer in self.layers:\n",
    "        h = layer(g, h)\n",
    "        \n",
    "      # 2. apply pooling to build fixed-size representation\n",
    "      g.ndata['h'] = h\n",
    "      g_emb = dgl.sum_nodes(g, 'h')\n",
    "      \n",
    "      # 3. apply classifier to get the logits \n",
    "      logits = self.classifier(g_emb)\n",
    "      \n",
    "      return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.) Define the training and testing loop\n",
    "\n",
    "### Use classic PyTorch training loop \n",
    "- Define the model parameters (num layers, GNN dimensions)\n",
    "- Define the training parameters (optimizer, learning rate, weight decay, number of epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation with loss=0.25 | accuracy=0.878: 100%|██████████| 50/50 [00:20<00:00,  2.44it/s]  \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import trange\n",
    "\n",
    "# with cuda?\n",
    "cuda = torch.cuda.is_available()\n",
    "device = 'cuda:0' if cuda else 'cpu'\n",
    "\n",
    "# declare model\n",
    "model = Model(\n",
    "  node_dim=g.ndata['attr'].shape[1],\n",
    "  out_dim=32,\n",
    "  num_layers=3,\n",
    "  num_classes=2\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# build optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=10e-3,\n",
    "    weight_decay=5e-4\n",
    ")\n",
    "\n",
    "# define loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# training \n",
    "val_loss = 10e5\n",
    "val_accuracy = 0.\n",
    "\n",
    "with trange(50) as t:\n",
    "  for epoch in t:\n",
    "    t.set_description('Validation with loss={} | accuracy={}'.format(val_loss, val_accuracy))\n",
    "    # A.) train for 1 epoch \n",
    "    model.train()\n",
    "    for graphs, labels in train_dataloader:\n",
    "\n",
    "        # 1. forward pass\n",
    "        labels = labels.to(device)\n",
    "        logits = model(graphs)\n",
    "\n",
    "        # 2. backward pass\n",
    "        loss = loss_fn(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # B.) validate\n",
    "    model.eval()\n",
    "    all_val_logits = []\n",
    "    all_val_labels = []\n",
    "    for graphs, labels in val_dataloader:\n",
    "        with torch.no_grad():\n",
    "            labels = labels.to(device)\n",
    "            logits = model(graphs)\n",
    "        all_val_logits.append(logits)\n",
    "        all_val_labels.append(labels)\n",
    "\n",
    "    all_val_logits = torch.cat(all_val_logits).cpu()\n",
    "    all_val_labels = torch.cat(all_val_labels).cpu()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_loss = round(loss_fn(all_val_logits, all_val_labels).item(), 2)\n",
    "        _, predictions = torch.max(all_val_logits, dim=1)\n",
    "        correct = torch.sum(predictions.to(int) == all_val_labels.to(int))\n",
    "        val_accuracy = round(correct.item() * 1.0 / len(all_val_labels), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
